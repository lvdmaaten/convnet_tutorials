{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCt-frpFH8oN"
   },
   "source": [
    "The tutorials use PyTorch. You will need to load the following dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This specific version of torchvision is needed to download the mnist set\n",
    "!pip install torchvision==0.9.1  torch==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqnl0AKVXIA4"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKeYuM-cIXxs"
   },
   "source": [
    "The code below may be helpful in visualizing PyTorch tensors as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZd_rI8edYIB"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show(img):\n",
    "    \"\"\"Show PyTorch tensor img as an image in matplotlib.\"\"\"\n",
    "    npimg = img.cpu().detach().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "    plt.grid(False)\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "def display_thumb(img):\n",
    "  display.display(transforms.Resize(128)(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzfEE578uSNp"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71LRkRxndajG"
   },
   "source": [
    "## First tutorial:\n",
    "\n",
    "In the first tutorial, we are going to train a logistic regressor on the MNIST dataset of handwritten digits. Next, we will turn this logistic regressor into a non-linear convolutional network.\n",
    "\n",
    "The following code will load the MNIST dataset. Run it and inspect some of the images and their labels to confirm they are correct.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349,
     "referenced_widgets": [
      "59a8e0ee48e14c9691224d013d6c46fe",
      "ee8b4317d860412fa60bca6d1d0c935a",
      "bcc108058dc4490986ec987c568b2034",
      "ab7e6d830cc74c14876a052480eb185a",
      "3a488dd9262d42ac9b119cd37e2e71c9",
      "229d85ab3245444c9ad5b57c6ec58688",
      "a9ccabebd2c6428594120631518c505c",
      "a739b97fb09848dbae2fb6d0fef09ef4",
      "41f12163cbd84febb7fade8126ed7d5e",
      "48dc62d211994fb1b3b323da3c8c8a26",
      "8f7373518a7840b38d00de7608a9e218",
      "e92daa0c7043415b8463dffd654e93e5",
      "df0848e4bca84d95b178cbe955417bc4",
      "10c91bce2e8b42c587557b0a649a79fe",
      "1a38c10f1d0e4f20a4958d453757f9e7",
      "70658583c62a40c28345d43ceb70810b",
      "e488365503444d9c8313fd2017d05f9e",
      "d677eff7d5a4494087a60ff1db4dab92",
      "200b60fab8514008a571603c6a2519f8",
      "34a38f1355e54a24ad0757e91e016ff4",
      "8f98aca9cfae490dab5dccf54b939ce0",
      "04f7f68d4f784cf19f942ee29c24ecc7",
      "99bb01a7fb144b149460669c65b22654",
      "466dc3fe5f2c447ebc9f7259e886e606",
      "e11d5108f5a74dd6b7143172c693dc6a",
      "590b36901152442088a4c5e05e781b3d",
      "2de5166b2a40479fb69c08e7fda49594",
      "655321e930014d03a986ab862d9c01a1",
      "bcbba5e1db1d498eb4b9ce545ff26d8a",
      "d57756abec8742db9d650c814b474137",
      "3c129350f337408f920706b3836528b9",
      "78f9f8dd4275405b96194f2507dae175"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7621,
     "status": "ok",
     "timestamp": 1586535092902,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "GX_ky5qC--uv",
    "outputId": "97a811cf-59f5-4bb5-be96-03e19190cd4b"
   },
   "outputs": [],
   "source": [
    "# Load the training and test dataset.\n",
    "mnist_train = datasets.MNIST('/tmp/mnist', train=True, download=True)\n",
    "mnist_test = datasets.MNIST('/tmp/mnist', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7559,
     "status": "ok",
     "timestamp": 1586535092902,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "E8dy7-kBHwco",
    "outputId": "66a535b5-83bc-48e0-f94a-1a79de8c3e66"
   },
   "outputs": [],
   "source": [
    "# Show a random image and the corresponding target.\n",
    "img, target = mnist_train[0]\n",
    "print('Label of image:', mnist_train.classes[target])\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKbXgidhWr6L"
   },
   "source": [
    "Next, we create a PyTorch dataloader for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ay0iiI1kWyMC"
   },
   "outputs": [],
   "source": [
    "# This ensures the MNIST dataset produces PyTorch tensors.\n",
    "mnist_train.transform = transforms.ToTensor()\n",
    "mnist_test.transform = transforms.ToTensor()\n",
    "\n",
    "# Size of the batches the data loader will produce.\n",
    "batch_size = 64\n",
    "\n",
    "# This creates the dataloaders.\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "liekFZzvYX9E"
   },
   "source": [
    "Next, implement a logistic regression model in PyTorch. Note that a logistic regressor uses a linear transformation of the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEw5YorSYkWF"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "  \"\"\"Linear logistic regression model.\"\"\"\n",
    "  \n",
    "  def __init__(self, input_size, num_classes):\n",
    "    super().__init__()\n",
    "    ###########################################################################\n",
    "    # TODO: Instantiate the layer here.                                       #\n",
    "    ###########################################################################\n",
    "    \n",
    "    \n",
    "  def forward(self, x):\n",
    "    ###########################################################################\n",
    "    # TODO: Apply the layer to the input.                                     #\n",
    "    ###########################################################################\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCerRXDHZFAS"
   },
   "source": [
    "We will use the following generic training loop for a PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVyEKl3OZLJw"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, data_loader, optimizer, num_epochs):\n",
    "    \"\"\"Simple training loop for a PyTorch model.\"\"\"\n",
    "    \n",
    "    # Make sure model is in training mode.\n",
    "    model.train()\n",
    "    \n",
    "    # Move model to the device.\n",
    "    model.to(device)\n",
    "    \n",
    "    # Exponential moving average of the loss.\n",
    "    ema_loss = None\n",
    "    \n",
    "    # Loop over epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "      # Loop over data.\n",
    "      for batch_idx, (data, target) in enumerate(data_loader):\n",
    "          data = data.to(device)\n",
    "          target = target.to(device)\n",
    "        \n",
    "          # Forward pass.\n",
    "          output = model(data)\n",
    "          loss = criterion(output, target)\n",
    "          \n",
    "          # Backward pass.\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          \n",
    "          # NOTE: It is important to call .item() on the loss before summing.\n",
    "          if ema_loss is None:\n",
    "            ema_loss = loss.item()\n",
    "          else:\n",
    "            ema_loss += (loss.item() - ema_loss) * 0.01 \n",
    "          \n",
    "          # Print out progress.\n",
    "          if batch_idx % 500 == 0:\n",
    "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), \n",
    "                    len(data_loader.dataset),\n",
    "                    100. * batch_idx / len(data_loader), ema_loss),\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oN8qTuGkZ-3X"
   },
   "source": [
    "**Question:** For the model you are currently using, is there any difference between using the model in `train` mode or using it in `eval` mode? \n",
    "\n",
    "Create an SGD optimizer and us it to train the logistic regressor on the MNIST training data for a few epochs. What loss function do you need to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37577,
     "status": "ok",
     "timestamp": 1586535122937,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "kC3z31pvadeP",
    "outputId": "db347216-2718-4aa1-d255-dae5afd5a83d"
   },
   "outputs": [],
   "source": [
    "# Create model, criterion, and optimizer.\n",
    "model = LogisticRegression(28 * 28, 10)\n",
    "###########################################################################\n",
    "# TODO: Create criterion and optimize here.                               #\n",
    "###########################################################################\n",
    "criterion = None\n",
    "optimizer = None\n",
    "\n",
    "\n",
    "# Train the model. If everything is correct, the loss should go below 0.45.\n",
    "train(model, criterion, train_loader, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0QN7Mhiar7d"
   },
   "source": [
    "Visualize the weights of the trained model. What do you see? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37796,
     "status": "ok",
     "timestamp": 1586535123165,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "gxletH44a4MX",
    "outputId": "1ba6c589-bcbb-4b86-a9ab-7fd4bc5bdfa1"
   },
   "outputs": [],
   "source": [
    "assert model.linear.weight.shape == (10, 28 * 28)\n",
    "show(torchvision.utils.make_grid(\n",
    "    model.linear.weight.view(10, 1, 28, 28),\n",
    "    normalize=True,\n",
    "    nrow=5,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lxf5NxQ6a5cT"
   },
   "source": [
    "Use the following function to measure the test accuracy of your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8UYWbqZYa9Qr"
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n",
    "    \n",
    "    # Make sure the model is in evaluation mode.\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    # We do not need to maintain intermediate activations while testing.\n",
    "    with torch.no_grad():\n",
    "      \n",
    "        # Loop over test data.\n",
    "        for data, target in data_loader:\n",
    "          \n",
    "            # Forward pass.\n",
    "            output = model(data.to(device))\n",
    "            \n",
    "            # Get the label corresponding to the highest predicted probability.\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            # Count number of correct predictions.\n",
    "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # Print test accuracy.\n",
    "    print('Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          correct, \n",
    "          len(data_loader.dataset),\n",
    "          100. * correct / len(data_loader.dataset)),\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37788,
     "status": "ok",
     "timestamp": 1586535123167,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "MrEY_dy5AKQV",
    "outputId": "a1d1e9f2-6d7f-45ec-be96-38a9dd30c767"
   },
   "outputs": [],
   "source": [
    "# Accuracy should be around 90%.\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1DV-MS2bxYq"
   },
   "source": [
    "**Question:** To have the logistic regressor output probabilities, they need to be processed through a softmax layer. Implement a softmax layer yourself. What numerical issues may arise in this layer? How can you solve them? Use the testing code to confirm you implemented it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38247,
     "status": "ok",
     "timestamp": 1586535123635,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "Dj4X2PnOfK9W",
    "outputId": "f3b3f1e7-682d-4fbc-cc57-367badf11b7b"
   },
   "outputs": [],
   "source": [
    "def bad_softmax(logits):\n",
    "  \"\"\"Computes softmax in a naive manner.\"\"\"\n",
    "  probs = logits.exp()\n",
    "  probs /= probs.sum(-1, keepdim=True)\n",
    "  return probs\n",
    "\n",
    "def good_softmax(logits):\n",
    "  \"\"\"Computes softmax in a numerically safe manner.\"\"\"\n",
    "  ###########################################################################\n",
    "  # TODO: Implement a more stable way to compute softmax                    #\n",
    "  ###########################################################################  \n",
    "  \n",
    "  return probs\n",
    "\n",
    "\n",
    "# Test the new softmax layer.\n",
    "logits = torch.rand((1, 20)) + 100\n",
    "print(bad_softmax(logits).sum(), \n",
    "      good_softmax(logits).sum())  # by definition, the correct value is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4C_J5S0RScXJ"
   },
   "source": [
    "Because of numerical issues like the one you just experiences, PyTorch code typically uses a `LogSoftmax` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgStX-ctjIms"
   },
   "source": [
    "**Question [optional]:** PyTorch automatically computes the backpropagation gradient of a module for you. However, it can be instructive to derive and implement your own backward function. Try and implement the backward function for your softmax module and confirm that it is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0xTuXo3dyWH"
   },
   "source": [
    "## Convolutions and images\n",
    "The spatial dimensions of the ouput image (width and height) depend on the spatial dimensions of the input image, kernel_size, padding, and striding. In order to build efficient convolutional networks, it's important to understand what the sizes are after after each convolutional layer.\n",
    "\n",
    "In this exersise you will derive the dependency between input and output image sizes. For the sake of simplicity we assume that the input tensor is _square_, i.e., width = height = image_size.\n",
    "\n",
    "We will use the nn.Conv2d layer here. We have not yet discussed what a convolutional layer is yet, but if you set the first two parameters (input channels and output channels) to 1, then this defines a basic convolution.\n",
    "\n",
    "If your code is correct, you should see 'OK'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61729,
     "status": "ok",
     "timestamp": 1586535147125,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "vg4CO_WDeLqh",
    "outputId": "1c8e4c4c-3b7d-494f-bc0a-4eb79dd758d0"
   },
   "outputs": [],
   "source": [
    "def compute_conv_output_size(image_size, kernel_size, padding, stride):\n",
    "  ###########################################################################\n",
    "  # Add code that computes the size of the image after a conv layer.        #\n",
    "  ###########################################################################\n",
    "    \n",
    "  return output_size\n",
    "\n",
    "\n",
    "# Compare the size of the output of nn.Conv2d with compute_convnet_output_size.\n",
    "for image_size in range(5, 21, 1):\n",
    "  # Shape: batch x channels x height x width.\n",
    "  input_tensor = torch.zeros((1, 1, image_size, image_size))\n",
    "  for kernel_size in 2, 3, 5, 7:\n",
    "    for padding in 0, 5:\n",
    "      for stride in 1, 2, 3, 4:\n",
    "        if kernel_size >= image_size:\n",
    "          continue\n",
    "        output_tensor = nn.Conv2d(1, 1, kernel_size, stride, padding)(input_tensor)\n",
    "        output_size = output_tensor.size(2)\n",
    "        predicted_output_size = compute_conv_output_size(\n",
    "            image_size, kernel_size, padding, stride)\n",
    "        assert output_size == predicted_output_size, (\n",
    "            f'ERROR: the real size is {output_size},'\n",
    "            f' but got {predicted_output_size}.'\n",
    "            f'\\nimage_size={image_size}'\n",
    "            f' kernel_size={kernel_size}'\n",
    "            f' padding={padding}'\n",
    "            f' stride={stride}'\n",
    "        )\n",
    "\n",
    "print('OK')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use the function you just implemented to compute the size of the output of a convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "EgLLXSScfwqK"
   },
   "outputs": [],
   "source": [
    "compute_conv_output_size(1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ncHkdY3df6R7"
   },
   "source": [
    "**Question [optional]:** Implement your own convolution operator **without** using any of PyTorch's (or numpy's) pre-defined convolutional functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RV30kha3vSsC"
   },
   "outputs": [],
   "source": [
    "def conv_naive(x, w, b, conv_param):\n",
    "    \"\"\"\n",
    "    A naive Python implementation of a convolution.\n",
    "    The input consists of an image tensor with height H and\n",
    "    width W. We convolve each input with a filter F, where the filter\n",
    "    has height HH and width WW.\n",
    "    Input:\n",
    "    - x: Input data of shape (H, W)\n",
    "    - w: Filter weights of shape (HH, WW)\n",
    "    - b: Bias for filter\n",
    "    - conv_param: A dictionary with the following keys:\n",
    "      - 'stride': The number of pixels between adjacent receptive fields in the\n",
    "        horizontal and vertical directions.\n",
    "      - 'pad': The number of pixels that will be used to zero-pad the input. \n",
    "        \n",
    "    During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides)\n",
    "    along the height and width axes of the input. Be careful not to modfiy the original\n",
    "    input x directly.\n",
    "    Returns an array.\n",
    "    - out: Output data, of shape (H', W') where H' and W' are given by\n",
    "      H' = 1 + (H + 2 * pad - HH) / stride\n",
    "      W' = 1 + (W + 2 * pad - WW) / stride\n",
    "    \"\"\"\n",
    "    out = None\n",
    "\n",
    "    H, W = x.shape\n",
    "    filter_height, filter_width = w.shape\n",
    "    stride, pad = conv_param['stride'], conv_param['pad']\n",
    "\n",
    "    # Check dimensions.\n",
    "    assert (W + 2 * pad - filter_width) % stride == 0, 'width does not work'\n",
    "    assert (H + 2 * pad - filter_height) % stride == 0, 'height does not work'\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Implement the convolutional forward pass.                         #\n",
    "    # Hint: you can use the function torch.nn.functional.pad for padding.     #\n",
    "    ###########################################################################\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dDNQP8VvVVj"
   },
   "source": [
    "You can test your implementation by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61712,
     "status": "ok",
     "timestamp": 1586535147127,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "7Leww6XRuC_0",
    "outputId": "0b7b6889-41c6-4079-db07-778d05831185"
   },
   "outputs": [],
   "source": [
    "# Make convolution module.\n",
    "w_shape = (4, 4)\n",
    "w = torch.linspace(-0.2, 0.3, steps=torch.prod(torch.tensor(w_shape))).reshape(w_shape)\n",
    "b = torch.linspace(-0.1, 0.2, steps=1)\n",
    "\n",
    "# Compute output of module and compare against reference values.\n",
    "x_shape = (4, 4)\n",
    "x = torch.linspace(-0.1, 0.5, steps=torch.prod(torch.tensor(x_shape))).reshape(x_shape)\n",
    "out = conv_naive(x, w, b, {'stride': 2, 'pad': 1})\n",
    "\n",
    "correct_out = torch.tensor([[0.156, 0.162],\n",
    "                            [0.036, -0.054]])\n",
    "\n",
    "# Compare your output to ours; difference should be around e-8\n",
    "print('Testing conv_forward_naive')\n",
    "rel_error = ((out - correct_out) / (out + correct_out + 1e-6)).mean()\n",
    "print('difference: ', rel_error)\n",
    "if abs(rel_error) < 1e-6:\n",
    "    print('Nice work! Your implementation of a convolution layer works correctly.')\n",
    "else:\n",
    "    print('Something is wrong. The output was expected to be {} but it was {}'.format(correct_out, out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4c_Whyy2ysdF"
   },
   "source": [
    "**Aside: Image processing via convolutions:**\n",
    "\n",
    "As fun way to gain a better understanding of the type of operation that convolutional layers can perform, we will set up an input containing two images and manually set up filters that perform common image processing operations (grayscale conversion and edge detection). The convolution forward pass will apply these operations to each of the input images. We can then visualize the results as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62399,
     "status": "ok",
     "timestamp": 1586535147823,
     "user": {
      "displayName": "Anton Bakhtin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq-QU8evTujx-PnMoIketNeW4yB_kgdtnRJ03IxnY=s64",
      "userId": "12331399045734156147"
     },
     "user_tz": 240
    },
    "id": "SygERdfdv6U-",
    "outputId": "6c60cbb1-ed93-4848-fffc-5ae236a11e46"
   },
   "outputs": [],
   "source": [
    "# Load image of a kitten and a puppy.\n",
    "kitten_uri = \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Persian_Cat_%28kitten%29.jpg/256px-Persian_Cat_%28kitten%29.jpg\"\n",
    "puppy_uri = \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Golde33443.jpg/256px-Golde33443.jpg\"\n",
    "kitten, puppy = imageio.imread(kitten_uri), imageio.imread(puppy_uri)\n",
    "\n",
    "img_size = 200   # Make this smaller if it runs too slow\n",
    "x = np.zeros((2, 3, img_size, img_size))\n",
    "x[0, :, :, :] = skimage.transform.resize(puppy, (img_size, img_size)).transpose((2, 0, 1))\n",
    "x[1, :, :, :] = skimage.transform.resize(kitten, (img_size, img_size)).transpose((2, 0, 1))\n",
    "x = torch.FloatTensor(x)\n",
    "\n",
    "# Set up a convolutional weights holding 2 filters, each 3x3\n",
    "w = torch.zeros((2, 3, 3, 3), dtype=torch.float)\n",
    "\n",
    "# The first filter converts the image to grayscale.\n",
    "# Set up the red, green, and blue channels of the filter.\n",
    "w[0, 0, :, :] = torch.tensor([[0, 0, 0], [0, 0.3, 0], [0, 0, 0]])\n",
    "w[0, 1, :, :] = torch.tensor([[0, 0, 0], [0, 0.6, 0], [0, 0, 0]])\n",
    "w[0, 2, :, :] = torch.tensor([[0, 0, 0], [0, 0.1, 0], [0, 0, 0]])\n",
    "\n",
    "# Second filter detects horizontal edges in the blue channel.\n",
    "w[1, 2, :, :] = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "\n",
    "# Vector of biases. We don't need any bias for the grayscale\n",
    "# filter, but for the edge detection filter we want to add 128\n",
    "# to each output so that nothing is negative.\n",
    "b = torch.tensor([0, 128], dtype=torch.float)\n",
    "\n",
    "# Compute the result of convolving each input in x with each filter in w,\n",
    "# offsetting by b, and storing the results in out.\n",
    "out = nn.functional.conv2d(x, w, b, stride=1, padding=1).numpy()\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\"Tiny helper to show images as uint8 and remove axis labels.\"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# Show the original images and the results of the conv operation\n",
    "plt.subplot(2, 3, 1)\n",
    "imshow_noax(puppy, normalize=False)\n",
    "plt.title('Original image')\n",
    "plt.subplot(2, 3, 2)\n",
    "imshow_noax(out[0, 0])\n",
    "plt.title('Grayscale')\n",
    "plt.subplot(2, 3, 3)\n",
    "imshow_noax(out[0, 1])\n",
    "plt.title('Edges')\n",
    "plt.subplot(2, 3, 4)\n",
    "imshow_noax(kitten, normalize=False)\n",
    "plt.subplot(2, 3, 5)\n",
    "imshow_noax(out[1, 0])\n",
    "plt.subplot(2, 3, 6)\n",
    "imshow_noax(out[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "convnet_tutorial1_filled.ipynb",
   "provenance": [
    {
     "file_id": "1Eq_v8eTk4XAxFXhjL6rk26gwfwvpZYBn",
     "timestamp": 1553454632964
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04f7f68d4f784cf19f942ee29c24ecc7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10c91bce2e8b42c587557b0a649a79fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a38c10f1d0e4f20a4958d453757f9e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "200b60fab8514008a571603c6a2519f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_04f7f68d4f784cf19f942ee29c24ecc7",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f98aca9cfae490dab5dccf54b939ce0",
      "value": 1
     }
    },
    "229d85ab3245444c9ad5b57c6ec58688": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2de5166b2a40479fb69c08e7fda49594": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d57756abec8742db9d650c814b474137",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bcbba5e1db1d498eb4b9ce545ff26d8a",
      "value": 0
     }
    },
    "34a38f1355e54a24ad0757e91e016ff4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_466dc3fe5f2c447ebc9f7259e886e606",
      "placeholder": "​",
      "style": "IPY_MODEL_99bb01a7fb144b149460669c65b22654",
      "value": " 1654784/? [00:00&lt;00:00, 1924711.94it/s]"
     }
    },
    "3a488dd9262d42ac9b119cd37e2e71c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3c129350f337408f920706b3836528b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41f12163cbd84febb7fade8126ed7d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f7373518a7840b38d00de7608a9e218",
       "IPY_MODEL_e92daa0c7043415b8463dffd654e93e5"
      ],
      "layout": "IPY_MODEL_48dc62d211994fb1b3b323da3c8c8a26"
     }
    },
    "466dc3fe5f2c447ebc9f7259e886e606": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48dc62d211994fb1b3b323da3c8c8a26": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "590b36901152442088a4c5e05e781b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59a8e0ee48e14c9691224d013d6c46fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bcc108058dc4490986ec987c568b2034",
       "IPY_MODEL_ab7e6d830cc74c14876a052480eb185a"
      ],
      "layout": "IPY_MODEL_ee8b4317d860412fa60bca6d1d0c935a"
     }
    },
    "655321e930014d03a986ab862d9c01a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78f9f8dd4275405b96194f2507dae175",
      "placeholder": "​",
      "style": "IPY_MODEL_3c129350f337408f920706b3836528b9",
      "value": " 0/4542 [00:00&lt;?, ?it/s]"
     }
    },
    "70658583c62a40c28345d43ceb70810b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78f9f8dd4275405b96194f2507dae175": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f7373518a7840b38d00de7608a9e218": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10c91bce2e8b42c587557b0a649a79fe",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df0848e4bca84d95b178cbe955417bc4",
      "value": 1
     }
    },
    "8f98aca9cfae490dab5dccf54b939ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "99bb01a7fb144b149460669c65b22654": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a739b97fb09848dbae2fb6d0fef09ef4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9ccabebd2c6428594120631518c505c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab7e6d830cc74c14876a052480eb185a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a739b97fb09848dbae2fb6d0fef09ef4",
      "placeholder": "​",
      "style": "IPY_MODEL_a9ccabebd2c6428594120631518c505c",
      "value": " 9920512/? [00:20&lt;00:00, 1061366.86it/s]"
     }
    },
    "bcbba5e1db1d498eb4b9ce545ff26d8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bcc108058dc4490986ec987c568b2034": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_229d85ab3245444c9ad5b57c6ec58688",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a488dd9262d42ac9b119cd37e2e71c9",
      "value": 1
     }
    },
    "d57756abec8742db9d650c814b474137": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d677eff7d5a4494087a60ff1db4dab92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df0848e4bca84d95b178cbe955417bc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e11d5108f5a74dd6b7143172c693dc6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2de5166b2a40479fb69c08e7fda49594",
       "IPY_MODEL_655321e930014d03a986ab862d9c01a1"
      ],
      "layout": "IPY_MODEL_590b36901152442088a4c5e05e781b3d"
     }
    },
    "e488365503444d9c8313fd2017d05f9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_200b60fab8514008a571603c6a2519f8",
       "IPY_MODEL_34a38f1355e54a24ad0757e91e016ff4"
      ],
      "layout": "IPY_MODEL_d677eff7d5a4494087a60ff1db4dab92"
     }
    },
    "e92daa0c7043415b8463dffd654e93e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70658583c62a40c28345d43ceb70810b",
      "placeholder": "​",
      "style": "IPY_MODEL_1a38c10f1d0e4f20a4958d453757f9e7",
      "value": " 32768/? [00:01&lt;00:00, 28639.26it/s]"
     }
    },
    "ee8b4317d860412fa60bca6d1d0c935a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
